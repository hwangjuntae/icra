import os
import cv2
import json
import torch
import numpy as np
import supervision as sv
import pycocotools.mask as mask_util
from pathlib import Path
from torchvision.ops import box_convert
import sys

# Grounded-SAM-2 ê²½ë¡œ ì¶”ê°€ ë° ì‘ì—… ë””ë ‰í† ë¦¬ ë³€ê²½
grounded_sam2_path = '/root/ws/src/risk_nav/src/Grounded-SAM-2'
sys.path.append(grounded_sam2_path)
os.chdir(grounded_sam2_path)  # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ Grounded-SAM-2ë¡œ ë³€ê²½

from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor
from grounding_dino.groundingdino.util.inference import load_model, load_image, predict

"""
Office í™˜ê²½ìš© Grounded SAM 2 ì„¤ì •
"""
# ì‚¬ë¬´ì‹¤ í™˜ê²½ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ê°ì²´ë“¤
TEXT_PROMPT = "computer. monitor. keyboard. mouse. chair. desk. lamp. phone. book. paper. pen. cup. bottle."
IMG_PATH = "/root/ws/src/risk_nav/src/sample/office_img.png"

# ëª¨ë¸ ê²½ë¡œë“¤ (ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½)
SAM2_CHECKPOINT = "./checkpoints/sam2.1_hiera_large.pt"
SAM2_MODEL_CONFIG = "configs/sam2.1/sam2.1_hiera_l.yaml"
GROUNDING_DINO_CONFIG = "grounding_dino/groundingdino/config/GroundingDINO_SwinT_OGC.py"
GROUNDING_DINO_CHECKPOINT = "gdino_checkpoints/groundingdino_swint_ogc.pth"

# ì„ê³„ê°’ ì„¤ì •
BOX_THRESHOLD = 0.25  # ë” ë§ì€ ê°ì²´ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ ë‚®ì¶¤
TEXT_THRESHOLD = 0.25
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
OUTPUT_DIR = Path("/root/ws/src/risk_nav/src/sample/outputs")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

print(f"ğŸ¢ Office ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
print(f"ğŸ“ ì´ë¯¸ì§€ ê²½ë¡œ: {IMG_PATH}")
print(f"ğŸ” ê²€ìƒ‰í•  ê°ì²´ë“¤: {TEXT_PROMPT}")
print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {DEVICE}")

# SAM2 ëª¨ë¸ ë¹Œë“œ
print("ğŸ¤– SAM2 ëª¨ë¸ì„ ë¡œë“œ ì¤‘...")
sam2_model = build_sam2(SAM2_MODEL_CONFIG, SAM2_CHECKPOINT, device=DEVICE)
sam2_predictor = SAM2ImagePredictor(sam2_model)

# Grounding DINO ëª¨ë¸ ë¡œë“œ
print("ğŸ¯ Grounding DINO ëª¨ë¸ì„ ë¡œë“œ ì¤‘...")
grounding_model = load_model(
    model_config_path=GROUNDING_DINO_CONFIG, 
    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT,
    device=DEVICE
)

# ì´ë¯¸ì§€ ë¡œë“œ
print("ğŸ“· ì´ë¯¸ì§€ë¥¼ ë¡œë“œ ì¤‘...")
image_source, image = load_image(IMG_PATH)

# SAM2 ì´ë¯¸ì§€ ì„¤ì •
sam2_predictor.set_image(image_source)

# Grounding DINOë¡œ ê°ì²´ íƒì§€
print("ğŸ” ê°ì²´ íƒì§€ ì¤‘...")
boxes, confidences, labels = predict(
    model=grounding_model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_THRESHOLD,
    text_threshold=TEXT_THRESHOLD
)

print(f"âœ… {len(boxes)}ê°œì˜ ê°ì²´ë¥¼ íƒì§€í–ˆìŠµë‹ˆë‹¤!")

# íƒì§€ëœ ê°ì²´ë“¤ ì¶œë ¥
for i, (box, conf, label) in enumerate(zip(boxes, confidences, labels)):
    print(f"  {i+1}. {label}: {conf:.3f}")

# ë°•ìŠ¤ë¥¼ SAM2 ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
h, w, _ = image_source.shape
boxes = boxes * torch.Tensor([w, h, w, h])
input_boxes = box_convert(boxes=boxes, in_fmt="cxcywh", out_fmt="xyxy").numpy()

# SAM2ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜
print("ğŸ–¼ï¸  ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰ ì¤‘...")
masks, scores, logits = sam2_predictor.predict(
    point_coords=None,
    point_labels=None,
    box=input_boxes,
    multimask_output=False,
)

# ê²°ê³¼ ì‹œê°í™”
print("ğŸ¨ ê²°ê³¼ë¥¼ ì‹œê°í™” ì¤‘...")

# íƒì§€ ê²°ê³¼ (ë°•ìŠ¤ + ë¼ë²¨)
# ë§ˆìŠ¤í¬ ì°¨ì›ì„ (N, 1, H, W) -> (N, H, W)ë¡œ ë³€ê²½
processed_masks = masks.squeeze(1).astype(bool)

detections = sv.Detections(
    xyxy=input_boxes,
    mask=processed_masks,
    class_id=np.array([i for i in range(len(labels))]),
    confidence=confidences.numpy()  # PyTorch tensorë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
)

# ë°•ìŠ¤ ì–´ë…¸í…Œì´í„°
box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

# ë¼ë²¨ ìƒì„±
annotated_labels = [
    f"{label} {confidence:.2f}"
    for label, confidence in zip(labels, confidences)
]

# ì–´ë…¸í…Œì´ì…˜ ì ìš©
annotated_image = box_annotator.annotate(
    scene=image_source.copy(), 
    detections=detections
)
annotated_image = label_annotator.annotate(
    scene=annotated_image, 
    detections=detections, 
    labels=annotated_labels
)

# ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
mask_annotator = sv.MaskAnnotator()
annotated_image_with_mask = mask_annotator.annotate(
    scene=annotated_image, 
    detections=detections
)

# ê²°ê³¼ ì €ì¥
print("ğŸ’¾ ê²°ê³¼ë¥¼ ì €ì¥ ì¤‘...")

# ë°•ìŠ¤ë§Œ ìˆëŠ” ì´ë¯¸ì§€
output_path_boxes = OUTPUT_DIR / "office_grounded_dino_result.jpg"
cv2.imwrite(str(output_path_boxes), annotated_image)

# ë§ˆìŠ¤í¬ í¬í•¨ ì´ë¯¸ì§€
output_path_masks = OUTPUT_DIR / "office_grounded_sam2_result.jpg"
cv2.imwrite(str(output_path_masks), annotated_image_with_mask)

# JSON ê²°ê³¼ ì €ì¥
results = {
    "image_path": IMG_PATH,
    "text_prompt": TEXT_PROMPT,
    "detections": [],
    "settings": {
        "box_threshold": BOX_THRESHOLD,
        "text_threshold": TEXT_THRESHOLD,
        "device": DEVICE
    }
}

for i, (box, conf, label, mask) in enumerate(zip(input_boxes, confidences, labels, masks)):
    # ë§ˆìŠ¤í¬ë¥¼ RLE í˜•ì‹ìœ¼ë¡œ ì¸ì½”ë”© (uint8 íƒ€ì…ìœ¼ë¡œ ë³€í™˜)
    mask_uint8 = (mask[0] * 255).astype(np.uint8)
    mask_rle = mask_util.encode(np.asfortranarray(mask_uint8))
    mask_rle["counts"] = mask_rle["counts"].decode("utf-8")
    
    detection = {
        "id": i + 1,
        "class_name": label,
        "confidence": float(conf),
        "bbox": [float(x) for x in box],
        "bbox_format": "xyxy",
        "mask": {
            "size": mask_rle["size"],
            "counts": mask_rle["counts"]
        }
    }
    results["detections"].append(detection)

# JSON íŒŒì¼ ì €ì¥
json_path = OUTPUT_DIR / "office_analysis_results.json"
with open(json_path, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)

print("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
print(f"ğŸ“Š ì´ {len(boxes)}ê°œì˜ ê°ì²´ë¥¼ íƒì§€í–ˆìŠµë‹ˆë‹¤.")
print(f"ğŸ“ ê²°ê³¼ íŒŒì¼:")
print(f"  - ë°•ìŠ¤ ê²°ê³¼: {output_path_boxes}")
print(f"  - ë§ˆìŠ¤í¬ ê²°ê³¼: {output_path_masks}")
print(f"  - JSON ê²°ê³¼: {json_path}")

# íƒì§€ëœ ê°ì²´ë³„ í†µê³„
object_counts = {}
for label in labels:
    object_counts[label] = object_counts.get(label, 0) + 1

print(f"\nğŸ“ˆ íƒì§€ëœ ê°ì²´ í†µê³„:")
for obj, count in object_counts.items():
    print(f"  - {obj}: {count}ê°œ") 